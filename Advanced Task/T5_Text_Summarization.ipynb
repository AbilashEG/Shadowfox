{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Text Summarization using T5 in Python\n", "This notebook demonstrates how to perform extractive summarization using the T5 (Text-to-Text Transfer Transformer) model from Hugging Face."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install transformers"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from transformers import T5Tokenizer, T5ForConditionalGeneration\n", "\n", "# Load the pre-trained T5 model and tokenizer from Hugging Face\n", "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n", "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n", "\n", "# Define the text you want to summarize\n", "text = '''\n", "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by animals including humans. \n", "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize \n", "its chance of successfully achieving its goals. Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that \n", "mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n", "As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. \n", "A quip in Tesler's Theorem says \"AI is whatever hasn't been done yet.\" For instance, optical character recognition is frequently excluded from things \n", "considered to be AI, having become a routine technology.\n", "Modern machine capabilities generally classified as AI include successfully understanding human speech, competing at the highest level in strategic game systems \n", "(such as chess and Go), autonomously operating cars, intelligent routing in content delivery networks, and military simulations.\n", "'''\n", "\n", "# Preprocess the input text (add \"summarize: \" as a prompt for T5)\n", "preprocessed_text = \"summarize: \" + text\n", "\n", "# Tokenize the input\n", "inputs = tokenizer.encode(preprocessed_text, return_tensors='pt', max_length=512, truncation=True)\n", "\n", "# Generate the summary (you can tweak the max_length and num_beams for better summarization)\n", "summary_ids = model.generate(inputs, max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n", "\n", "# Decode and print the summary\n", "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n", "print(\"Summary:\", summary)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}